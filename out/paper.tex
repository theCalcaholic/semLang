\documentclass{article}
% generated by Madoko, version 1.0.1
%mdk-data-line={1}


\usepackage[heading-base={2},section-num={False},bib-label={True}]{madoko2}
\usepackage{acl2016}


\begin{document}



%mdk-begin-texraw
%mdk-data-line={15}
\aclfinalcopy

%mdk-data-line={18}
\mdxtitleblockstart{}
%mdk-data-line={18}
\mdxtitle{\mdline{18}Überblick über die Aufgabe des POS-Tagging und bestehende Lösungen}%mdk

%mdk-data-line={21}
\mdxsubtitle{\mdline{21}Seminararbeit zum Thema Sprachverarbeitung}%mdk
\mdxauthorstart{}
%mdk-data-line={26}
\mdxauthorname{\mdline{26}Tobias Knöppler}%mdk

%mdk-data-line={29}
\mdxauthoraddress{\mdline{29}Fachbereich Informatik, Uni Hamburg}%mdk

%mdk-data-line={32}
\mdxauthoremail{\mdline{32}tobias@knoeppler.net}%mdk
\mdxauthorend
%mdk-data-line={41}
\mdxtitlefooter{\mdline{41}Eingereicht am 10.08.2016}%mdk
\mdtitleauthorrunning{}{}\mdxtitleblockend%mdk

%mdk-data-line={20}
\noindent\mdline{20}\newpage{}\mdline{20}%mdk

%mdk-data-line={22}
\begin{abstract}%mdk

%mdk-data-line={23}
\noindent\mdline{23}\mdbr
\mdline{23}
Ich stelle in dieser Arbeit die grundlegende Aufgabe von Part-Of-Speech-Tagging und die allgemeine Herangehensweise, sowie einiger konkreter Beispiele dar.\mdline{24}\mdline{24}
Diese Arbeit soll nicht dazu dienen, konkrete POS-Tagging-Verfahren in ihrer Tiefe zu erklären, sondern das die Problemstellung einordnen zu können.%mdk
%mdk
\end{abstract}%mdk

%mdk-data-line={28}
\section{\mdline{28}1.\hspace*{0.5em}\mdline{28}Einleitung}\label{sec-einleitung}%mdk%mdk

%mdk-data-line={30}
\noindent\mdline{30}POS-Tagging (\mdline{30}\textquotedblleft{}Part-Of-Speech-Tagging\textquotedblright{}\mdline{30}) bezeichnet das Versehen der Worte innerhalb eines Textes mit den zugehörigen Wortarten. Diese Informationen werden an die Worte in Form von sogenannten Tags angefügt, daher der Name.
Als Grundlage für die Entscheidung, zu welcher Wortart ein Wort gehört, werden Wörterbücher, Syntax, der Kontext und statistische Analysen herangezogen.
Ist ein Wort erst einmal mit der zugehörigen Wortart versehen, kann dies für vielfältige weitere Aufgaben im Bereich des Natural Language Processing nützlich sein\mdline{32} \mdline{32}- so lässt sich zum Beispiel in einigen Fällen eine semantische Mehrdeutigkeit durch Kenntnis der Wortart auflösen.%mdk

%mdk-data-line={34}
\section{\mdline{34}2.\hspace*{0.5em}\mdline{34}Verfahren}\label{sec-verfahren}%mdk%mdk

%mdk-data-line={36}
\subsection{\mdline{36}2.1.\hspace*{0.5em}\mdline{36}Text-Korpora}\label{sec-text-korpora}%mdk%mdk

%mdk-data-line={37}
\noindent\mdline{37}Der Schwierigkeitsgrad, ebenso wie der Nutzen von POS-Tagging wird sehr stark durch das verwendete Tag-Set bestimmt. Die bereits aus der Schule bekannten Wortarten werden hier in der Regel wesentlich genauer spezifiert, um einen größeren Nutzen aus den Tags ziehen zu können.%mdk

%mdk-data-line={39}
\mdline{39}Hierzu sind Textsammlungen (Textcorpora) nötig, die bereits mit Tags versehen wurden.
Dabei existieren sehr homogene Korpora für spezielle Zwecke, ebenso wie möglichst heterogene Korpora. Außerdem bringen die meisten Korpora ihr eigenes Tag Set mit. Insgesamt ist es also für das POS Tagging essenziell, den richtigen Text-Korpus je nach Anwendungsfall zu wählen (oder zu erzeugen).%mdk

%mdk-data-line={42}
\mdline{42}Historisch von Bedeutung ist hier der Brown Copus (für die englische Sprache), welcher etwa 1.000.000 Worte enthält. Diese wurden im Laufe der Zeit mit Tags versehen und diese Tags wurden mit der wachsenden Genauigkeit der Tagger und viel manueller Arbeit korrigiert, sodass mittlerweile für den Korpus eine nahezu hundertprozentige Genauigkeit besteht.
Mittlerweile wurde der Brown Corpus jedoch für die meisten Anwendungen von einer Vielzahl jüngerer und umfangreicherer Kopora abgelöst, da die Menge an Worten im Brown Corpus für die Trainingsmethoden vieler Tagger schlichtweg unzureichend ist.%mdk

%mdk-data-line={45}
\mdline{45}Ein prominenter Korpus für die englische Sprache ist beispielsweise der British National Corpus, der mit etwa 100 Millionen Worten\mdline{45} \mdline{45}- zusammengesetzt aus 90\% geschriebenen Texten und 10\% transkribierten gesprochenen Texten\mdline{45} \mdline{45}- versucht eine möglichst große Bandbreite an modernem Englisch abzudecken. Um es dennoch zu ermöglichen, den Hintergrund der Texte beim Taggen zu berücksichtigen, sind die Texte in \mdline{45}\textquotedblleft{}domain\textquotedblright{}\mdline{45}, \mdline{45}\textquotedblleft{}time\textquotedblright{}\mdline{45} und \mdline{45}\textquotedblleft{}medium\textquotedblright{}\mdline{45} eingeteilt, wobei \mdline{45}\textquotedblleft{}domain\textquotedblright{}\mdline{45} die Textgattung, \mdline{45}\textquotedblleft{}time\textquotedblright{}\mdline{45} die Zeit zu der der Text entstanden ist und \mdline{45}\textquotedblleft{}medium\textquotedblright{}\mdline{45} das Transportmedium (z.B. Zeitungsartikel oder buch) bezeichnet.%mdk

%mdk-data-line={47}
\mdline{47}Ein weiterer Korpus ist die Penn Treebank (PTB). Dieser Korpus entstand, indem Textsammlungen geparsed und im Nachhinein manuell korrigiert wurden. Er ist zusammengesetzt aus verschiedenen Textquellen, darunter der gesamte Brown Corpus, eine Sammlung von Telefonattransskripten, etwa einer Million Worten aus Zeitungstexten des Wall Street Journal, et cetera. Der gesamte Korpus ist mit POS-Tags versehen, während etwa zwei Drittel zusätzlich vollständig geparsed ist (d.h. es wurde ein Syntaxbaum für jeden Satz erzeugt).%mdk

%mdk-data-line={49}
\mdline{49}Für die deutsche Sprache gibt es zum Beispiel den TIGER Corpus, der aus etwa 900.000 Worten aus schriftlichen Nachrichtentexten der Frankfurter Rundschau aufgebaut ist\mdline{49}~(\mdcite{imsweb}{8})\mdline{49}.%mdk

%mdk-data-line={51}
\subsection{\mdline{51}2.2.\hspace*{0.5em}\mdline{51}Entscheidungsgrundlagen}\label{sec-entscheidungsgrundlagen}%mdk%mdk

%mdk-data-line={52}
\noindent\mdline{52}Oft lässt sich die Wortart direkt von einem Wort ableiten\mdline{52} \mdline{52}- ohne weitere Informationen zu berücksichtigen. Das ist dann der Fall, wenn das Wort in einem Wörterbuch enthalten (also bereits bekannt) ist und es nur eine einzige Wortart haben kann (d.h. keine Mehrdeutigkeit der Wortart besteht).\mdline{52}\mdline{52}
Leider ist in den meisten kein ausreichend vollständiges Wörterbuch verfügbar. Die eigentliche Herausforderung bilden deshalb die übrigen Worte, also unbekannte Worte und solche, die mehreren Wortarten zugehörig sein können. Im deutschen ist die erste Kategorie besonders groß, da es eine unendliche Zahl valider, zusammengesetzter Worte gibt, was ein vollständiges Wörterbuch unmöglich macht. In der englischen Sprache spielen zusammengesetzte Worte zwar eine kleinere Rolle, aber dafür existieren zahlreiche Worte, die mehreren Wortarten angehören können, insbesondere, da Substantive sich nicht durch Großschreibung von anderen Wortarten abheben.%mdk

%mdk-data-line={55}
\mdline{55}Um diese Fälle, in denen sich die Wortart auf triviale Weise entscheiden lässt, dennoch zu disambiguieren, bieten sich mehrere Ansätze.%mdk

%mdk-data-line={57}
\mdline{57}Die naivste Methode ist, einfach jedem Wort die Wortart zuzuweisen, in der es statistisch am häufigsten auftritt. Das nützt zwar im Blick auf unbekannte Worte nichts, aber für mehrdeutige Wortarten verbessert diese Technik das Resultat deutlich.
Zudem ist leicht einzusehen, dass auf diese Weise noch immer keine zufriedenstellende Genauigkeit erreicht werden kann; da gerade im Englischen viele Worte in mehr als einer Wortart jeweils häufig auftreten (z.b. fish).%mdk

%mdk-data-line={60}
\mdline{60}Um unbekannte Worte klassifizieren zu können, können gewisse Eigenschaften der Worte als betrachtet werden, in dem Versuch, aus diesen eine Wahrscheinlichkeit für unterschiedliche Wortarten abzuleiten, beispielsweise die Anzahl von Ziffern oder Großbuchstaben im Wort oder ob es einen Bindestrich enthält. Mit handgeschriebenen Regeln oder Maschinenlernverfahren kann dies in die Entscheidung für eine Wortart miteinfließen.%mdk

%mdk-data-line={62}
\mdline{62}Der nächste Schritt ist, den syntaktischen Kontext des Wortes mit in die Klassifizierung einzubeziehen. Ein simples Beispiel hierfür ist, dass ein Substantiv nach einem Artikel wesentlich wahrscheinlicher ist, als ein Verb. Die Betrachtung eines größeren Kontextes um das Wort herum führt jedoch in der Regel zu proportional größerem Rechenaufwand.%mdk

%mdk-data-line={64}
\mdline{64}Dasselbe gilt in noch größerem Maße für das Einbeziehen des semantischen Kontextes. Dies erlaubt zwar einige Fälle zu entscheiden, in denen die Wortart rein syntaktisch nicht auflösbar wäre, aber der Aufwand hierfür ist so gewaltig, dass dies bei den meisten aktuellen POS-Taggern keine Rolle spielt.%mdk

%mdk-data-line={66}
\mdline{66}Die genannten Merkmale bilden zusammen die Eigenschaften auf deren Grundlage die meisten POS-Tagger trainiert werden.%mdk

%mdk-data-line={68}
\subsection{\mdline{68}2.3.\hspace*{0.5em}\mdline{68}Genauigkeit}\label{sec-genauigkeit}%mdk%mdk

%mdk-data-line={70}
\noindent\mdline{70}Die Genauigkeit eines POS-Taggers wird in der Regel in \% der richtig eingeordneten Worte angegeben. Dieser Wert ist jedoch mit Vorsicht zu genießen, da erstens nicht immer klar ist, ob diese Trefferquote sich auf den bekannte oder unbekannte Worte bezieht und zweitens der Nutzen eines POS-Taggers für viele Anwendungen noch mehr von der Genauigkeit abhängt, mit der er ganze Sätze vollständig tagged.%mdk

%mdk-data-line={72}
\mdline{72}Es bietet sich an, einen Tagger, der nur die Häufigkeitsverteilung eines Wortes auf die Wortklassen betrachtet (unigram-most-likely), als Grundlage für die Untergrenze der angestrebten Genauigkeit zu wählen (erstmals vorgeschlagen von\mdline{72}~Gale u. a.~(\mdcite{gale1992}{1992})\mdline{72}).%mdk

%mdk-data-line={74}
\mdline{74}Die Genauigkeit dieses Verfahrens wurde (nach\mdline{74}~Charniak~(\mdcite{charniak1993}{1993})\mdline{74}) bei 90-91\% korrekt getaggter Worte ermittelt.%mdk

%mdk-data-line={76}
\mdline{76}Als Obergrenze der erreichbaren Genauigkeit wird üblicherweise der Gold Standard verwendet, in diesem Fall die Übereinstimmung menschlicher Experten. Diese beläuft sich auf etwa 96-97\% (nach\mdline{76}~Marcus u. a.~(\mdcite{marcus1993}{1993})\mdline{76}).
\mdline{77}(Voutilainen,~\mdcite{voutilainen1995}{1995})\mdline{77} hat jedoch herausgefunden, dass 100\% Übereinstimmung erreichbar sind, wenn die Experten sich absprechen. Daraus lässt sich ableiten, dass die Abweichungen nicht durch Mehrdeutigkeiten in der Sprache, sondern vielmehr durch Fehler der Experten zustande gekommen waren.\mdline{77}\mdline{77}
Dies ist wichtig, da einige der heutigen POS-Tagger Genauigkeiten von 97\% erreichen, womit der Gold Standard ansonsten bereits erreicht wäre.%mdk

%mdk-data-line={80}
\subsection{\mdline{80}2.4.\hspace*{0.5em}\mdline{80}Ansätze}\label{sec-anstze}%mdk%mdk

%mdk-data-line={82}
\noindent\mdline{82}Es existieren zahllose Ansätze und Implementationen für POS-Tagger, sodass es schwierig ist, im Zuge dieses Artikels einen oder zumindest einige wenige herauszuheben, zumal selbst noch dann bei weitem zu viele Verfahren übrig bleiben, wenn man nur diejenigen mit der höchsten Genauigkeit betrachtet. Deshalb ist die folgende Auswahl von POS-Taggern einigermaßen willkürlich zusammengestellt, mit dem Ziel einen groben Einblick zu bieten.\mdline{82}\mdline{82}
Auf die genaue Funktionsweise einzugehen würde den Rahmen dieser Arbeit jedoch sprengen, deshalb begnüge ich mich mit einigen wichtigen Eigenschaften, die der allgemeinen Einordnung der Verfahren dienen sollen.\mdline{83}\mdline{83}
Die Daten zur Genauigkeit der Implementationen sind auf dem Teil der Penn Treebank, welcher auf Texten des \mdline{84}\emph{Wall Street Journal}\mdline{84} beruht, gemessen und der ACL-Wiki\mdline{84}\mdfootnote{1}{%mdk-data-line={117}
%mdk-data-line={117}
\noindent\mdline{117}https://www.aclweb.org/aclwiki/index.php?title=POS\mdline{117}\emph{Tagging}\mdline{117}\mdbr
\mdline{117}(State\mdline{117}\_\mdline{117}of\mdline{117}\_\mdline{117}the\mdline{117}\_\mdline{117}art)\mdline{117}\#\mdline{117}WSJ%mdk
\label{fn-aclwiki}%mdk%mdk
}\mdline{84} entnommen.%mdk

%mdk-data-line={86}
\subsubsection{\mdline{86}2.4.1.\hspace*{0.5em}\mdline{86}Hidden Markov Model (HMM)}\label{sec-hidden-markov-model-hmm}%mdk%mdk

%mdk-data-line={88}
\noindent\mdline{88}Einige der frühen POS-Tagger basieren auf Hidden Markov Modellen. Bei diesem Verfahren wird jeweils ein nach Anzahl Worten begrenzter Kontext vor und/oder nach dem zu klassifizierenden Wort betrachtet und auf dieser Grundlage eine statistische Wahrscheinlichkeit für die jeweiligen Wortarten ermittelt. Verwendet man für die Länge dieses Kontexts 1 (nur das betrachtete Wort), so erhält man eben das Modell, welches die Untergrenze der erstrebten Genauigkeit bildet (vlgl. 2.3). Das Betrachten sehr großer Kontexte hingegen scheitert am Rechenaufwand, welcher exponentiell mit der Größe des Kontexts wächst.\mdline{88}\mdline{88}
Ein POS-Tagger, der auf einem Hidden Markov Modell beruht, ist beispielsweise der TnT-Tagger\mdline{89}~(Brants,~\mdcite{brants2000}{2000})\mdline{89}, der eine Genauigkeit von 96,46\% erreicht.%mdk

%mdk-data-line={91}
\subsubsection{\mdline{91}2.4.2.\hspace*{0.5em}\mdline{91}Neuronale Netze}\label{sec-neuronale-netze}%mdk%mdk

%mdk-data-line={93}
\noindent\mdline{93}Zahlreiche POS-Tagger\mdline{93} \mdline{93}- darunter einige mit Genauigkeiten über 97\%\mdline{93} \mdline{93}-beruhen auf verschiedenen Arten neuronaler Netze. Dabei sind diverse Varianten eines einfachen Perzeptrons ebenso vertreten, wie komplexere Netze; etwa Long-Short-Term-Memory-Netzwerke.\mdline{93}\mdline{93}
Allen gemeinsam ist das grundlegende Verfahren: Die Wort wird mit bestimmten, ausgesuchten Eigenschaften kodiert und das neuronale Netz kombiniert die (in der Regel zahlreichen) Eigenschaften der einzelnen Worte solcherart zu Metaeigenschaften, dass diese möglichst viel über die Wortart des Wortes aussagen. Bevor das Neuronale Netz dies effizient tun kann, muss es mit bekannten Worten und ihren dazugehörigen Wortarten trainiert werden. Damit ist dies ein Fall von überwachtem Lernen.\mdline{94}\mdline{94}
Wie bei allen Maschinenlern-Algorithmen ist bei diesem Verfahren eine Sorgfältige Auswahl der verwendeten Eigenschaften (Features) der Worte und ein gutes Preprocessing derselben essentiell. In einigen Fällen stellt das Neuronale Netz gar selbst nur einen weiteren Preprocessing-Schritt dar, der die Dimensionalität der Wort-Feature-Vektoren verringert (indem ein kleines Perceptronen-Layer auf ein großes folgt) und dabei möglichst viel vom Informationsgehalt der Daten bewahrt. Danach folgt dann der eigentliche Klassifizierer.\mdline{95}\mdline{95}
Die besten Ergebnisse der auf Neuronalen Netzen basierenden POS-Tagger (namentlich das Bidirectional LSTM-CRF Model von\mdline{96}~Huang u. a.~(\mdcite{huang2015}{2015})\mdline{96}) erreichen eine Genauigkeit von 97,55\% und gehören damit auch insgesamt zu den besten verfügbaren POS-Taggern.%mdk

%mdk-data-line={98}
\subsubsection{\mdline{98}2.4.3.\hspace*{0.5em}\mdline{98}Nearest Neighbour Algorithmus}\label{sec-nearest-neighbour-algorithmus}%mdk%mdk

%mdk-data-line={100}
\noindent\mdline{100}Dieser Algorithmus beruht auf der simplen Idee, einem unbekannten Wort (das wieder als Vektor von Eigenschaften/Features angegeben ist) die Wortart des ähnlichsten, bereits bekannten Wortes (des \mdline{100}"\mdline{100}nächsten Nachbarn) zuzuweisen. In einer etwas verbesserten Form des Verfahrens werden aus den zur Klassifizierung verwendeten, bekannten Worten diejenigen aussortiert, die für die Einordnung keines der Worte in der Trainingsmenge relevant waren. In einem weiteren Optimierungsschritt, welcher in unüberwachtem Lernen besteht, werden aus einer unklassifizierten Wortmenge all jene Worte zum reduzierten Klassifizierer hinzugefügt, die mit diesem signifikant schlechter als mit dem ursprünglichen Nearest Neighbour Klassifizierer zugeordnet werden können.\mdline{100}\mdline{100}
In dieser Form erreicht der Tagger eine Genauigkeit von 97,50\%. Er wurde von\mdline{101}~Søgaard~(\mdcite{sogaard2011}{2011})\mdline{101} entworfen.%mdk

%mdk-data-line={103}
\section{\mdline{103}3.\hspace*{0.5em}\mdline{103}Fazit}\label{sec-fazit}%mdk%mdk

%mdk-data-line={105}
\noindent\mdline{105}Aufgrund der erreichten Trefferquoten aktueller POS-Tagger wird POS-Tagging oft als gelöstes Problem betrachtet. Dagegen ist jedoch einzuwenden, das%mdk

%mdk-data-line={107}
\begin{enumerate}[noitemsep,topsep=\mdcompacttopsep]%mdk

%mdk-data-line={107}
\item\mdline{107}eine Trefferquote von 97,50\% noch immer bedeutet, dass beispielsweise ein Satz mit 12 Worten nur zu 73,79\% vollständig richtig disambiguiert wird (der tatsächliche Wert dürfte noch niedriger sein, da es in einem langen Satz schwieriger ist, einzelne Worte zu klassifizieren, als in einem kurzen, da der Kontext komplexer wird) und%mdk

%mdk-data-line={108}
\item\mdline{108}es viele Gebiete gibt, in denen die Datenlage (d.h. die Verfügbarkeit guter Textkorpora) den Einsatz vieler POS-Tagger nur begrenzt zulässt oder zumindest ihre Genauigkeit schmälert. Dazu zählen sowohl viele Sprachen, zu denen es wenige Daten gibt, als auch speziellere Textsorten, wie 

%mdk-data-line={109}
\begin{itemize}[noitemsep,topsep=\mdcompacttopsep]%mdk

%mdk-data-line={109}
\item\mdline{109}gesprochene Sprache%mdk

%mdk-data-line={110}
\item\mdline{110}Chatnachrichten%mdk

%mdk-data-line={111}
\item\mdline{111}etc.%mdk
%mdk
\end{itemize}%mdk
\mdline{113}Für diese Textsorten werden mitunter deutlich schlechtere Ergebnisse erziehlt.%mdk
%mdk
\end{enumerate}%mdk

%mdk-data-line={115}
\noindent\mdline{115}Aus diesem Grund halte ich es für voreilig, POS-Tagging als vollends gelöstes Problem zu betrachten, auch wenn die aktuellen Resultate bereits viele Zwecken genügen.%mdk

%mdk-data-line={119;out/paper-bib.bbl.mdk:1}
%mdk-data-line={119;out/paper-bib.bbl.mdk:2}
\mdsetrefname{References}%mdk
{\mdbibindent{0}%mdk
\begin{thebibliography}{8}%mdk
\label{sec-bibliography}%mdk

%mdk-data-line={sources.bib:39}
\bibitem{brants2000}Thorsten Brants. \textquotedblleft{}TnT \textendash{} Statistical Part-of-Speech Tagging\textquotedblright{}. 2000. \href{http://www.coli.uni-saarland.de/~thorsten/tnt/}{{\ttfamily http://\hspace{0pt}www.\hspace{0pt}coli.\hspace{0pt}uni-\hspace{0pt}saarland.\hspace{0pt}de/\hspace{0pt}\textasciitilde{}thorsten/\hspace{0pt}tnt/\hspace{0pt}}}.\label{brants2000}%mdk%mdk

%mdk-data-line={sources.bib:23}
\bibitem{charniak1993}Eugene Charniak. \textquotedblleft{}Statistical Language Learning\textquotedblright{}. 1993.\label{charniak1993}%mdk%mdk

%mdk-data-line={sources.bib:17}
\bibitem{gale1992}William Gale, Kenneth Ward Church, und Yarowsky David. \textquotedblleft{}Estimating Upper and Lower Bounds on the Performance of Word-Sense Disambiguation Programs\textquotedblright{}. 1992.\label{gale1992}%mdk%mdk

%mdk-data-line={sources.bib:50}
\bibitem{huang2015}Zhiheng Huang, Wei Xu, und Kai Yu. \textquotedblleft{}Bidirectional LSTM-CRF Models for Sequence Tagging\textquotedblright{}. 2015.\label{huang2015}%mdk%mdk

%mdk-data-line={sources.bib:29}
\bibitem{marcus1993}Mitchell P.~Marcus, Beatrice Santorini, und Mary Ann Marcinkiewicz. \textquotedblleft{}Building a Large Annotated Corpus of English: The Penn Treebank\textquotedblright{}. 1993.\label{marcus1993}%mdk%mdk

%mdk-data-line={sources.bib:56}
\bibitem{sogaard2011}Anders Søgaard. \textquotedblleft{}Semi-Supervised Condensed Nearest Neighbor for Part-of-Speech Tagging\textquotedblright{}. 2011.\label{sogaard2011}%mdk%mdk

%mdk-data-line={sources.bib:35}
\bibitem{voutilainen1995}Atro Voutilainen. 1995.\label{voutilainen1995}%mdk%mdk

%mdk-data-line={sources.bib:14}
\bibitem{imsweb} \href{http://www.ims.uni-stuttgart.de/}{{\ttfamily http://\hspace{0pt}www.\hspace{0pt}ims.\hspace{0pt}uni-\hspace{0pt}stuttgart.\hspace{0pt}de/\hspace{0pt}}}.\label{imsweb}%mdk%mdk
\par%mdk
\end{thebibliography}}%mdk%mdk%mdk


\end{document}
